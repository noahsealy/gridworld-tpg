{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions (ignore) scroll down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will use Downing fig 11 for testing on this\n",
    "class Figure11:\n",
    "    def __init__ (self, rows, cols, win_state, start_state, memory_size,\n",
    "                    legal_move, illegal_move, out_of_bounds, memory_repeat, goal_reached):\n",
    "        self.memory = []\n",
    "        self.memory_position = 0\n",
    "        self.memory_limit = memory_size #20\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.start_state = start_state\n",
    "        self.win_state = win_state\n",
    "        self.current_state = self.start_state\n",
    "        self.legal_move = legal_move\n",
    "        self.illegal_move = illegal_move\n",
    "        self.out_of_bounds = out_of_bounds\n",
    "        self.memory_repeat = memory_repeat\n",
    "        self.goal_reached = goal_reached\n",
    "        \n",
    "    def sample_action (self):\n",
    "        rand = random.uniform(0, 1)\n",
    "        if (rand >= 0) and (rand < 0.25):\n",
    "            return 0\n",
    "        elif (rand >= 0.25) and (rand < 0.5):\n",
    "            return 1\n",
    "        elif (rand >= 0.5) and (rand < 0.75):\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "        \n",
    "    def reset (self):\n",
    "        self.memory = []\n",
    "        self.memory_position = 0\n",
    "        self.current_state = self.start_state\n",
    "        return self.current_state\n",
    "        \n",
    "    # just reset for now...\n",
    "    def close (self):\n",
    "        self.current_state = self.start_state\n",
    "        return 1\n",
    "    \n",
    "    def check_win (self):\n",
    "        if self.current_state == self.win_state:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def step (self, action):\n",
    "        # north\n",
    "        if action == 0:\n",
    "            next = (self.current_state[0] - 1, self.current_state[1])\n",
    "        # south\n",
    "        elif action == 1:\n",
    "            next = (self.current_state[0] + 1, self.current_state[1])\n",
    "        # east\n",
    "        elif action == 2:\n",
    "            next = (self.current_state[0], self.current_state[1] + 1)\n",
    "        # west\n",
    "        else:\n",
    "            next = (self.current_state[0], self.current_state[1] - 1)\n",
    "\n",
    "        terminate = False\n",
    "        reward = 0\n",
    "        # check if move is legal\n",
    "        if (next[0] >= 0 and next[0] <= (self.rows-1)) and (next[1] >= 0 and next[1] <= (self.cols-1)):            \n",
    "            illegal = 0\n",
    "            if (next == (1, 2)) or (next == (1, 3)) or (next == (2, 2)) or (next == (2, 3)):\n",
    "                illegal = 1\n",
    "                    \n",
    "            if (illegal == 0):\n",
    "                self.current_state = next\n",
    "                reward += self.legal_move\n",
    "                #reward += 0.1\n",
    "                #reward -= 0.01\n",
    "            else:\n",
    "                reward += self.illegal_move\n",
    "                #reward -= 0.01\n",
    "                #reward -= 1\n",
    "                #reward = reward\n",
    "        else:\n",
    "            reward += self.out_of_bounds\n",
    "            #reward -= 0.01\n",
    "            #reward -= 1\n",
    "            #reward = reward\n",
    "            \n",
    "        # punish repeat states within last 20 states\n",
    "        if self.current_state in self.memory:\n",
    "            reward += self.memory_repeat\n",
    "            #reward -= 0.01\n",
    "            #reward -= 1\n",
    "            #reward = reward\n",
    "        \n",
    "        if self.check_win():\n",
    "            reward += self.goal_reached\n",
    "            #reward += 100\n",
    "            terminate = True\n",
    "        \n",
    "        # add new state to memory\n",
    "        if len(self.memory) <= self.memory_limit:\n",
    "            (self.memory).append(self.current_state)\n",
    "        # after memory is full, begin overriding it\n",
    "        else:\n",
    "            if self.memory_position < self.memory_limit:\n",
    "                self.memory[self.memory_position] = self.current_state\n",
    "                self.memory_position += 1\n",
    "            else:\n",
    "                self.memory_position = 0\n",
    "                self.memory[self.memory_position] = self.current_state\n",
    "        \n",
    "        return self.current_state, reward, terminate\n",
    "    \n",
    "    def animate_path(self, sequence):\n",
    "        current_map = np.zeros((5, 5))\n",
    "        # add barrier\n",
    "        current_map[(1, 2)] = 5\n",
    "        current_map[(1, 3)] = 5\n",
    "        current_map[(2, 2)] = 5\n",
    "        current_map[(2, 3)] = 5\n",
    "        current_map[self.win_state] = 8\n",
    "\n",
    "        # animate the run!\n",
    "        for i in range(len(sequence)):\n",
    "            time.sleep(0.5)\n",
    "            if i == 0:\n",
    "                current_map[sequence[i]] = 1\n",
    "                clear_output(wait=True)\n",
    "                print(0)\n",
    "                print(current_map)\n",
    "            else:\n",
    "                current_map[sequence[i-1]] = 0\n",
    "                current_map[sequence[i]] = 1\n",
    "                clear_output(wait=True)\n",
    "                print(i)\n",
    "                print(current_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will use Downing fig 12 for testing on this\n",
    "class Figure12:\n",
    "    def __init__ (self, rows, cols, win_state, start_state, memory_size,\n",
    "                      legal_move, illegal_move, out_of_bounds, memory_repeat, goal_reached):\n",
    "        self.memory = []\n",
    "        self.memory_position = 0\n",
    "        self.memory_limit = memory_size #20\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.start_state = start_state\n",
    "        self.win_state = win_state\n",
    "        self.current_state = self.start_state\n",
    "        self.legal_move = legal_move\n",
    "        self.illegal_move = illegal_move\n",
    "        self.out_of_bounds = out_of_bounds\n",
    "        self.memory_repeat = memory_repeat\n",
    "        self.goal_reached = goal_reached\n",
    "        \n",
    "    def sample_action (self):\n",
    "        rand = random.uniform(0, 1)\n",
    "        if (rand >= 0) and (rand < 0.25):\n",
    "            return 0\n",
    "        elif (rand >= 0.25) and (rand < 0.5):\n",
    "            return 1\n",
    "        elif (rand >= 0.5) and (rand < 0.75):\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "        \n",
    "    def reset (self):\n",
    "        self.current_state = self.start_state\n",
    "        self.memory = []\n",
    "        self.memory_position = 0\n",
    "        return self.current_state\n",
    "        \n",
    "    # just reset for now...\n",
    "    def close (self):\n",
    "        self.current_state = self.start_state\n",
    "        return 1\n",
    "    \n",
    "    def check_win (self):\n",
    "        if self.current_state == self.win_state:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def step (self, action):\n",
    "        # north\n",
    "        if action == 0:\n",
    "            next = (self.current_state[0] - 1, self.current_state[1])\n",
    "        # south\n",
    "        elif action == 1:\n",
    "            next = (self.current_state[0] + 1, self.current_state[1])\n",
    "        # east\n",
    "        elif action == 2:\n",
    "            next = (self.current_state[0], self.current_state[1] + 1)\n",
    "        # west\n",
    "        else:\n",
    "            next = (self.current_state[0], self.current_state[1] - 1)\n",
    "\n",
    "        terminate = False\n",
    "        reward = 0\n",
    "        # check if move is legal\n",
    "        if (next[0] >= 0 and next[0] <= (self.rows-1)) and (next[1] >= 0 and next[1] <= (self.cols-1)):            \n",
    "            illegal = 0\n",
    "            if (next == (2, 0)) or (next == (1, 1)) or (next == (2, 1)) or (next == (1, 3)) or (next == (2, 3)) or (next == (2, 4)):\n",
    "                illegal = 1\n",
    "                    \n",
    "            if (illegal == 0):\n",
    "                self.current_state = next\n",
    "                reward += self.legal_move\n",
    "                #reward -= 0.01\n",
    "            else:\n",
    "                reward += self.illegal_move\n",
    "                #reward -= 1\n",
    "                #reward = reward\n",
    "        else:\n",
    "            reward += self.out_of_bounds\n",
    "            #reward -= 1\n",
    "            #reward = reward\n",
    "            \n",
    "        # punish repeat states within last 20 states\n",
    "        if self.current_state in self.memory:\n",
    "            reward += self.memory_repeat\n",
    "            #reward -= 1\n",
    "        \n",
    "        if self.check_win():\n",
    "            reward += self.goal_reached\n",
    "            terminate = True\n",
    "        \n",
    "        # add new state to memory\n",
    "        if len(self.memory) <= self.memory_limit:\n",
    "            (self.memory).append(self.current_state)\n",
    "        # after memory is full, begin overriding it\n",
    "        else:\n",
    "            if self.memory_position < self.memory_limit:\n",
    "                self.memory[self.memory_position] = self.current_state\n",
    "                self.memory_position += 1\n",
    "            else:\n",
    "                self.memory_position = 0\n",
    "                self.memory[self.memory_position] = self.current_state\n",
    "        \n",
    "        return self.current_state, reward, terminate\n",
    "    \n",
    "    def animate_path(self, sequence):\n",
    "        current_map = np.zeros((5, 5))\n",
    "        # add barrier\n",
    "        current_map[(2, 0)] = 5\n",
    "        current_map[(1, 1)] = 5\n",
    "        current_map[(2, 1)] = 5\n",
    "        current_map[(1, 3)] = 5\n",
    "        current_map[(2, 3)] = 5\n",
    "        current_map[(2, 4)] = 5\n",
    "        current_map[self.win_state] = 8\n",
    "\n",
    "        # animate the run!\n",
    "        for i in range(len(sequence)):\n",
    "            time.sleep(0.5)\n",
    "            if i == 0:\n",
    "                current_map[sequence[i]] = 1\n",
    "                clear_output(wait=True)\n",
    "                print(0)\n",
    "                print(current_map)\n",
    "            else:\n",
    "                current_map[sequence[i-1]] = 0\n",
    "                current_map[sequence[i]] = 1\n",
    "                clear_output(wait=True)\n",
    "                print(i)\n",
    "                print(current_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will use Downing fig 13 for testing on this\n",
    "class Figure13:\n",
    "    def __init__ (self, rows, cols, win_state, start_state, memory_size,\n",
    "                      legal_move, illegal_move, out_of_bounds, memory_repeat, goal_reached):\n",
    "        self.memory = []\n",
    "        self.memory_position = 0\n",
    "        self.memory_limit = memory_size #20\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.start_state = start_state\n",
    "        self.win_state = win_state\n",
    "        self.current_state = self.start_state\n",
    "        self.legal_move = legal_move\n",
    "        self.illegal_move = illegal_move\n",
    "        self.out_of_bounds = out_of_bounds\n",
    "        self.memory_repeat = memory_repeat\n",
    "        self.goal_reached = goal_reached\n",
    "        \n",
    "    def reset (self):\n",
    "        self.current_state = self.start_state\n",
    "        self.memory = []\n",
    "        self.memory_position = 0\n",
    "        return self.current_state\n",
    "        \n",
    "    # just reset for now...\n",
    "    def close (self):\n",
    "        self.current_state = self.start_state\n",
    "        return 1\n",
    "    \n",
    "    def check_win (self):\n",
    "        if self.current_state == self.win_state:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def step (self, action):\n",
    "        # north\n",
    "        if action == 0:\n",
    "            next = (self.current_state[0] - 1, self.current_state[1])\n",
    "        # south\n",
    "        elif action == 1:\n",
    "            next = (self.current_state[0] + 1, self.current_state[1])\n",
    "        # east\n",
    "        elif action == 2:\n",
    "            next = (self.current_state[0], self.current_state[1] + 1)\n",
    "        # west\n",
    "        else:\n",
    "            next = (self.current_state[0], self.current_state[1] - 1)\n",
    "\n",
    "        terminate = False\n",
    "        reward = 0\n",
    "        # check if move is legal\n",
    "        if (next[0] >= 0 and next[0] <= (self.rows-1)) and (next[1] >= 0 and next[1] <= (self.cols-1)):            \n",
    "            illegal = 0\n",
    "            if (next == (2, 0)) or (next == (1, 1)) or (next == (2, 1)) or (next == (1, 3)) or (next == (2, 3)) or (next == (3, 3)) or (next == (3, 4)):\n",
    "                illegal = 1\n",
    "                    \n",
    "            if (illegal == 0):\n",
    "                self.current_state = next\n",
    "                reward += self.legal_move\n",
    "                #reward -= 0.01\n",
    "            else:\n",
    "                reward += self.illegal_move\n",
    "                #reward -= 1\n",
    "                #reward = reward\n",
    "        else:\n",
    "            reward += self.out_of_bounds\n",
    "            #reward -= 1\n",
    "            #reward = reward\n",
    "            \n",
    "        # punish repeat states within last 20 states\n",
    "        if self.current_state in self.memory:\n",
    "            reward += self.memory_repeat\n",
    "            #reward -= 1\n",
    "            #reward = reward\n",
    "        \n",
    "        if self.check_win():\n",
    "            reward += self.goal_reached\n",
    "            terminate = True\n",
    "        \n",
    "        # add new state to memory\n",
    "        if len(self.memory) <= self.memory_limit:\n",
    "            (self.memory).append(self.current_state)\n",
    "        # after memory is full, begin overriding it\n",
    "        else:\n",
    "            if self.memory_position < self.memory_limit:\n",
    "                self.memory[self.memory_position] = self.current_state\n",
    "                self.memory_position += 1\n",
    "            else:\n",
    "                self.memory_position = 0\n",
    "                self.memory[self.memory_position] = self.current_state\n",
    "        \n",
    "        return self.current_state, reward, terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate (team, state):\n",
    "    top_learner = None\n",
    "    action = None   \n",
    "\n",
    "    # get best learner\n",
    "    actVars = {'frameNum':random.randrange(0, 100000000)}\n",
    "\n",
    "    #valid_learners = [lrnr for lrnr in team.learners if lrnr.isActionAtomic()]\n",
    "    valid_learners = [lrnr for lrnr in team.learners]\n",
    "    \n",
    "    top_learner = max(valid_learners, key=lambda lrnr: lrnr.bid(state, actVars=actVars))\n",
    "    \n",
    "    if top_learner == None:\n",
    "        print('No top learner found!')\n",
    "        return None, 0\n",
    "    else:\n",
    "        actions = []\n",
    "#         top_q = 0\n",
    "        top_q = -10000000\n",
    "        top_action = None\n",
    "        \n",
    "        for entry in team.q_table:\n",
    "            if entry['learner'] == str(top_learner.id):\n",
    "                actions.append(entry['action'])\n",
    "                if entry['q'] >= top_q: # greater than OR greater than or equal to??\n",
    "                    top_q = entry['q']\n",
    "                    top_action = entry['action']            \n",
    "\n",
    "    # we don't use e-greedy here as exploration is not for testing, only training\n",
    "    return top_learner, top_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a given team after training\n",
    "def post_training_run (env_name, team):\n",
    "    env.reset()\n",
    "    l_t, a_t = evaluate(team, env.current_state)\n",
    "    actions = []\n",
    "    learners = []\n",
    "    states = []\n",
    "    #print(states)\n",
    "    states.append(env.current_state)\n",
    "    learners.append(l_t)\n",
    "    actions.append(a_t)\n",
    "    t = 0\n",
    "    if env_name == 'fig9':\n",
    "        t_max = 100\n",
    "    else:\n",
    "        t_max = 50\n",
    "    total_reward = 0\n",
    "    while t < t_max:\n",
    "        s_next, reward, isDone = env.step(a_t)\n",
    "        states.append(s_next)\n",
    "        learners.append(l_t)\n",
    "        actions.append(a_t)\n",
    "        total_reward += reward\n",
    "        if isDone:\n",
    "            return states, actions, learners, total_reward\n",
    "        l_next, a_next = evaluate(team, env.current_state)\n",
    "        \n",
    "#         if l_t.id != l_next.id:\n",
    "#             update(team, l_next, a_t, l_t, reward, alpha, epsilon)\n",
    "            \n",
    "        a_t = a_next\n",
    "        l_t = l_next\n",
    "        t = t + 1\n",
    "    return states, actions, learners, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update (team, next_learner, action, learner, reward, alpha, discount):\n",
    "    \n",
    "    # find the greatest q value out of possible actions for learner t+1\n",
    "    second_max_q = 0\n",
    "    for second_learner in team.q_table:\n",
    "        if second_learner['learner'] == str(next_learner.id):\n",
    "            if second_learner['q'] > second_max_q:\n",
    "                second_max_q = second_learner['q']\n",
    "    \n",
    "    # find the current learner and q update\n",
    "    for first_learner in team.q_table:\n",
    "        if first_learner['learner'] == str(learner.id) and first_learner['action'] == action:\n",
    "            # equation 1 from tpg pdf\n",
    "            first_learner['q'] += alpha * (reward + (discount * second_max_q) - first_learner['q'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load file naming conventions\n",
    "### saved-runs/{envName}_{memory_size}_{legalMove}_{illegalMove}_{outOfBounds}_{memoryRepeat}_{goalReached}_{teamPopSize}_{pActAtom}_{nRegisters}_{initMaxActProgSize}_{initMaxTeamSize}_{maxTeamSize}_{gap}_{lemarkian}_{epsilon}_{alpha}_{discount}_{run}_{gen}.pk1\n",
    "\n",
    "## Naming conventions for figure loader\n",
    "### saved-figures/{envName}_{memory_size}_{legalMove}_{illegalMove}_{outOfBounds}_{memoryRepeat}_{goalReached}_{teamPopSize}_{pActAtom}_{nRegisters}_{initMaxActProgSize}_{initMaxTeamSize}_{maxTeamSize}_{gap}_{lemarkian}_{epsilon}_{alpha}_{discount}_{run}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Curve Averaged over 5 Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File saved-figures/fig11_20_0.1_-0.01_-0.01_-0.01_100_50_1.0_8_64_0_0_2_4_0.5_0.3_0.2_0.7_0.5_0.0_0.5_0.5_0.5_0.5_0_0.1_0.05_0.45_0.csv does not exist: 'saved-figures/fig11_20_0.1_-0.01_-0.01_-0.01_100_50_1.0_8_64_0_0_2_4_0.5_0.3_0.2_0.7_0.5_0.0_0.5_0.5_0.5_0.5_0_0.1_0.05_0.45_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f288eaa492e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved-figures/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0menvName\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemorySize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlegalMove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0millegalMove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutOfBounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemoryRepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoalReached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteamPopSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpActAtom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnRegisters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitMaxProgSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnActRegisters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitMaxActProgSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitMaxTeamSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxTeamSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpLrnDel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpLrnAdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpLrnMut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpProgMut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpActMut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpInstDel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpInstAdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpInstSwp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpInstMut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlamarckian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/local/pkg/python/root-python-3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/pkg/python/root-python-3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/pkg/python/root-python-3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/pkg/python/root-python-3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/pkg/python/root-python-3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File saved-figures/fig11_20_0.1_-0.01_-0.01_-0.01_100_50_1.0_8_64_0_0_2_4_0.5_0.3_0.2_0.7_0.5_0.0_0.5_0.5_0.5_0.5_0_0.1_0.05_0.45_0.csv does not exist: 'saved-figures/fig11_20_0.1_-0.01_-0.01_-0.01_100_50_1.0_8_64_0_0_2_4_0.5_0.3_0.2_0.7_0.5_0.0_0.5_0.5_0.5_0.5_0_0.1_0.05_0.45_0.csv'"
     ]
    }
   ],
   "source": [
    "# environmental parameters\n",
    "# envName = 'basegpfig11'\n",
    "# envName = 'basegpfig12'\n",
    "# envName = 'basegpfig13'\n",
    "# envName = 'randomstartsbasegpfig13'\n",
    "# envName = 'fig9'\n",
    "envName = 'fig11'\n",
    "# envName = 'fig12'\n",
    "# envName = 'fig13'\n",
    "# envName = 'oppositesamplesfig13'\n",
    "# envName = 'leftgoalfig12'\n",
    "# envName = 'leftgoalfig13'\n",
    "# envName = 'randomstartsfig9'\n",
    "# envName = 'randomstartsfig11'\n",
    "# envName = 'randomstartsfig12'\n",
    "# envName = 'randomstartsfig13'\n",
    "goalReached = 100\n",
    "memorySize = 20\n",
    "legalMove = 0.1\n",
    "illegalMove = -0.01\n",
    "outOfBounds = -0.01\n",
    "memoryRepeat = -0.01\n",
    "goalReached = 100\n",
    "# RL parameters\n",
    "epsilon = 0.1\n",
    "alpha = 0.05\n",
    "discount = 0.45#0.9\n",
    "# run parameters\n",
    "lamarckian = 0\n",
    "# trainer parameters\n",
    "\n",
    "initMaxProgSize = 64#24\n",
    "nRegisters = 8#4\n",
    "nActRegisters = 0#64#0\n",
    "initMaxActProgSize = 0#8#0\n",
    "\n",
    "pLrnDel=0.3#0.7\n",
    "pLrnAdd=0.2#0.7\n",
    "pLrnMut=0.7#0.3\n",
    "pProgMut=0.5#0.66\n",
    "pActMut=0.0#0.7#0.33\n",
    "pInstDel=0.5\n",
    "pInstAdd=0.5\n",
    "pInstSwp=0.5\n",
    "pInstMut=0.5\n",
    "\n",
    "initMaxTeamSize = 2\n",
    "maxTeamSize = 4#5#4\n",
    "gap = 0.5\n",
    "\n",
    "teamPopSize = 50\n",
    "pActAtom = 1.0\n",
    "\n",
    "figs = []\n",
    "\n",
    "for i in range(20):\n",
    "    figs.append(pd.read_csv('saved-figures/'+envName+'_'+str(memorySize)+'_'+str(legalMove)+'_'+str(illegalMove)+'_'+str(outOfBounds)+'_'+str(memoryRepeat)+'_'+str(goalReached)+'_'+str(teamPopSize)+'_'+str(pActAtom)+'_'+str(nRegisters)+'_'+str(initMaxProgSize)+'_'+str(nActRegisters)+'_'+str(initMaxActProgSize)+'_'+str(initMaxTeamSize)+'_'+str(maxTeamSize)+'_'+str(gap)+'_'+str(pLrnDel)+'_'+str(pLrnAdd)+'_'+str(pLrnMut)+'_'+str(pProgMut)+'_'+str(pActMut)+'_'+str(pInstDel)+'_'+str(pInstAdd)+'_'+str(pInstSwp)+'_'+str(pInstMut)+'_'+str(lamarckian)+'_'+str(epsilon)+'_'+str(alpha)+'_'+str(discount)+'_'+str(i)+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if (envName == 'randomstartsfig11') or (envName == 'randomstartsfig12') or (envName == 'randomstartsfig13'):\n",
    "#     starts = pd.read_csv('saved-figures/'+envName+'_starts.csv')\n",
    "#     print(starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(figs)):\n",
    "    plt.plot(figs[i]['average_score'].tolist(), label='Run: '+str(i))\n",
    "    \n",
    "plt.title(\"lqtpg Runs\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.xlim(0,100)\n",
    "plt.ylabel(\"Average Fitness\")\n",
    "plt.ylim(-30,130)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(figs)):\n",
    "    plt.plot(figs[i]['max_score'].tolist(), label='Run: '+str(i+1))\n",
    "    \n",
    "plt.title(\"lqtpg Runs\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.xlim(0,100)\n",
    "plt.ylabel(\"Max Fitness\")\n",
    "plt.ylim(-30,130)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxes_averaged = np.zeros(100)\n",
    "for i in range(len(figs)):\n",
    "    maxes_averaged += figs[i]['max_score']\n",
    "    if (i > 0):\n",
    "        maxes_averaged /= 2\n",
    "    \n",
    "# maxes_averaged = sum(figs['max_score'])/len(figs['max_score'])\n",
    "\n",
    "plt.plot(maxes_averaged, label='Over 20 Runs')\n",
    "    \n",
    "plt.title(\"lqtpg Runs\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.xlim(0,100)\n",
    "plt.ylabel(\"Max Fitness\")\n",
    "plt.ylim(-30,130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(figs)):\n",
    "    plt.plot(figs[i]['median_score'].tolist(), label='Run: '+str(i+1))\n",
    "    \n",
    "plt.title(\"lqtpg Runs\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.xlim(0,100)\n",
    "plt.ylabel(\"Median Fitness\")\n",
    "plt.ylim(-30,130)\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 5\n",
    "plt.plot(figs[run]['max_score'].tolist(), label=f'Run: {run+1}')\n",
    "plt.title(\"lqtpg Runs\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.xlim(0,100)\n",
    "plt.ylabel(\"Max Fitness\")\n",
    "plt.ylim(-20,130)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(figs[run]['average_score'].tolist(), label=f'Run: {run+1}')\n",
    "plt.title(\"lqtpg Runs\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.xlim(0,100)\n",
    "plt.ylabel(\"Average Fitness\")\n",
    "plt.ylim(-20,130)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(figs[run]['median_score'].tolist(), label=f'Run: {run+1}')\n",
    "plt.title(\"lqtpg Runs\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.xlim(0,100)\n",
    "plt.ylabel(\"Median Fitness\")\n",
    "plt.ylim(-20,130)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Individual Champion Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the champ's gen and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpg.agent import loadAgent\n",
    "def load_champion(agent_path):\n",
    "    agent = loadAgent(agent_path)\n",
    "    agent.configFunctionsSelf()\n",
    "    print(agent.team)\n",
    "    return agent.team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct the agent, using the parameters in the file name\n",
    "run = 5\n",
    "gen = 80\n",
    "file_name = 'saved-runs/'+envName+'_'+str(memorySize)+'_'+str(legalMove)+'_'+str(illegalMove)+'_'+str(outOfBounds)+'_'+str(memoryRepeat)+'_'+str(goalReached)+'_'+str(teamPopSize)+'_'+str(pActAtom)+'_'+str(nRegisters)+'_'+str(initMaxProgSize)+'_'+str(nActRegisters)+'_'+str(initMaxActProgSize)+'_'+str(initMaxTeamSize)+'_'+str(maxTeamSize)+'_'+str(gap)+'_'+str(pLrnDel)+'_'+str(pLrnAdd)+'_'+str(pLrnMut)+'_'+str(pProgMut)+'_'+str(pActMut)+'_'+str(pInstDel)+'_'+str(pInstAdd)+'_'+str(pInstSwp)+'_'+str(pInstMut)+'_'+str(lamarckian)+'_'+str(epsilon)+'_'+str(alpha)+'_'+str(discount)+'_'+str(run)+'_'+str(gen)+'.pk1'\n",
    "print(file_name)\n",
    "champ = load_champion(file_name)\n",
    "\n",
    "if (envName == 'fig11') or (envName == 'randomstartsfig11'):\n",
    "    env = Figure11(5, 5, (0, 4), (4, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "elif (envName == 'fig12') or (envName == 'randomstartsfig12'):\n",
    "    env = Figure12(5, 5, (0, 4), (4, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "elif envName == 'leftgoalfig12':\n",
    "    env = Figure12(5, 5, (0, 0), (4, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "elif envName == 'leftgoalfig13':\n",
    "    env = Figure13(5, 5, (2, 0), (4, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)\n",
    "else: # fig13 and randomstartsfig13\n",
    "    env = Figure13(5, 5, (2, 4), (4, 0), memorySize, legalMove, illegalMove, outOfBounds, memoryRepeat, goalReached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(champ.q_table)\n",
    "for q_value in champ.q_table:\n",
    "    print(str(q_value['learner']) + ' ' + str(q_value['action']) + ' ' + str(q_value['q']))\n",
    "\n",
    "#print('\\n\\n\\n')\n",
    "for i in range(10):\n",
    "    print('Run: ' + str(i) + ' -----')\n",
    "    states, actions, learners, score = post_training_run(envName, champ)\n",
    "    print(score)\n",
    "    for j in range(len(states)):\n",
    "        print(str(states[j]) + '  Action: ' + str(actions[j]) + ' Learner: ' + str(learners[j].id))\n",
    "    print('\\n\\n')\n",
    "#print(champ.q_table)\n",
    "#print('\\n\\n\\n')\n",
    "for q_value in champ.q_table:\n",
    "    print(str(q_value['learner']) + ' ' + str(q_value['action']) + ' ' + str(q_value['q']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for post training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig = plt.figure()\n",
    "x = [0, 1, 2]\n",
    "y = [0, 1, 2]\n",
    "\n",
    "lines = plt.plot([], 'bo')\n",
    "line = lines[0]\n",
    "\n",
    "plt.xlim(-5, 5)\n",
    "plt.ylim(-5, 5)\n",
    "\n",
    "def animate(frame):\n",
    "    #line.set_data((0, 1), (states[frame][1], states[frame][0]))\n",
    "#     obs_x = [1]\n",
    "#     obs_y = [1]\n",
    "#     plt.plot(obs_x, obs_y, 'ro')\n",
    "    # obstacles\n",
    "    obs_x = [2, 1, 2, 1, 2, 3, 3]\n",
    "    obs_y = [0, 1, 1, 3, 3, 3, 4]\n",
    "    # win state\n",
    "    win_x = [2]\n",
    "    win_y = [4]\n",
    "    # the animated trajectory\n",
    "    plt.cla()\n",
    "    plt.xlim(-5, 5)\n",
    "    plt.ylim(-5, 5)\n",
    "    traj_x = []\n",
    "    traj_y = []\n",
    "    for i in range(frame+1):\n",
    "        traj_x.append(states[i][0])\n",
    "        traj_y.append(states[i][1])\n",
    "    # plot all of the points\n",
    "    plt.plot(obs_x, obs_y, 'ro')\n",
    "    plt.plot(win_x, win_y, 'go')\n",
    "#     plt.plot(traj_x, traj_y, 'b-')\n",
    "    plt.plot(states[frame][0], states[frame][1], 'yo')\n",
    "        \n",
    "anim = FuncAnimation(fig, animate, frames = len(states), interval = 1000)\n",
    "#file_name = 'saved-animations/'+envName+'_'+str(memorySize)+'_'+str(legalMove)+'_'+str(illegalMove)+'_'+str(outOfBounds)+'_'+str(memoryRepeat)+'_'+str(goalReached)+'_'+str(teamPopSize)+'_'+str(pActAtom)+'_'+str(nRegisters)+'_'+str(initMaxProgSize)+'_'+str(nActRegisters)+'_'+str(initMaxActProgSize)+'_'+str(initMaxTeamSize)+'_'+str(maxTeamSize)+'_'+str(gap)+'_'+str(pLrnDel)+'_'+str(pLrnAdd)+'_'+str(pLrnMut)+'_'+str(pProgMut)+'_'+str(pActMut)+'_'+str(pInstDel)+'_'+str(pInstAdd)+'_'+str(pInstSwp)+'_'+str(pInstMut)+'_'+str(lamarckian)+'_'+str(epsilon)+'_'+str(alpha)+'_'+str(discount)+'_'+str(run)+'_'+str(gen)+'.gif'\n",
    "#anim.save(file_name, dpi=1000, writer=PillowWriter(fps=200))\n",
    "plt.grid(alpha=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
