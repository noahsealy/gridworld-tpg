{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Figure9:\n",
    "    def __init__ (self, rows, cols, win_state, start_state):\n",
    "        self.memory = []\n",
    "        self.memory_position = 0\n",
    "        self.memory_limit = 20\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.start_state = start_state\n",
    "        self.win_state = win_state\n",
    "        self.current_state = self.start_state\n",
    "        \n",
    "    def reset (self):\n",
    "        self.current_state = self.start_state\n",
    "        return self.current_state\n",
    "        \n",
    "    # just reset for now...\n",
    "    def close (self):\n",
    "        self.current_state = self.start_state\n",
    "        return 1\n",
    "    \n",
    "    def check_win (self):\n",
    "        if self.current_state == self.win_state:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def step (self, action):\n",
    "        # north\n",
    "        if action == 0:\n",
    "            next = (self.current_state[0] - 1, self.current_state[1])\n",
    "        # south\n",
    "        elif action == 1:\n",
    "            next = (self.current_state[0] + 1, self.current_state[1])\n",
    "        # east\n",
    "        elif action == 2:\n",
    "            next = (self.current_state[0], self.current_state[1] + 1)\n",
    "        # west\n",
    "        else:\n",
    "            next = (self.current_state[0], self.current_state[1] - 1)\n",
    "\n",
    "        terminate = False\n",
    "        reward = 0\n",
    "        # check if move is legal\n",
    "        if (next[0] >= 0 and next[0] <= (self.rows-1)) and (next[1] >= 0 and next[1] <= (self.cols-1)):            \n",
    "            illegal = 0\n",
    "            \n",
    "            if (next == (1, 6)) or (next == (2, 6)) or (next == (3, 6)) or (next == (5, 2)) or (next == (5, 3)) or (next == (5, 4)) or (next == (5, 5)) or (next == (4, 9)) or (next == (4, 8)) or (next == (5, 8)) or (next == (6, 8)) or (next == (6, 5)) or (next == (7, 5)) or (next == (8, 5)) or (next == (9, 5)):\n",
    "                illegal = 1\n",
    "                    \n",
    "            if (illegal == 0):\n",
    "                self.current_state = next\n",
    "                reward += 0.1\n",
    "                #reward -= 0.01\n",
    "            else:\n",
    "                reward -= 0.01\n",
    "                #reward -= 1\n",
    "                #reward = reward\n",
    "        else:\n",
    "            reward -= 0.01\n",
    "            #reward -= 1\n",
    "            #reward = reward\n",
    "            \n",
    "        # punish repeat states within last 20 states\n",
    "        if self.current_state in self.memory:\n",
    "            reward -= 0.01\n",
    "            #reward -= 1\n",
    "            #reward = reward\n",
    "        \n",
    "        if self.check_win():\n",
    "            reward += 100\n",
    "            terminate = True\n",
    "        \n",
    "        # add new state to memory\n",
    "        if len(self.memory) <= self.memory_limit:\n",
    "            (self.memory).append(self.current_state)\n",
    "        # after memory is full, begin overriding it\n",
    "        else:\n",
    "            if self.memory_position < self.memory_limit:\n",
    "                self.memory[self.memory_position] = self.current_state\n",
    "                self.memory_position += 1\n",
    "            else:\n",
    "                self.memory_position = 0\n",
    "                self.memory[self.memory_position] = self.current_state\n",
    "        \n",
    "        return self.current_state, reward, terminate\n",
    "    \n",
    "    def animate_path(self, sequence):\n",
    "        current_map = np.zeros((10, 10))\n",
    "        # add barrier\n",
    "        current_map[(1, 6)] = 5\n",
    "        current_map[(2, 6)] = 5\n",
    "        current_map[(3, 6)] = 5\n",
    "        current_map[(4, 9)] = 5\n",
    "        current_map[(4, 8)] = 5\n",
    "        current_map[(5, 8)] = 5\n",
    "        current_map[(6, 8)] = 5\n",
    "        current_map[(5, 2)] = 5\n",
    "        current_map[(5, 3)] = 5\n",
    "        current_map[(5, 4)] = 5\n",
    "        current_map[(5, 5)] = 5\n",
    "        current_map[(6, 5)] = 5\n",
    "        current_map[(7, 5)] = 5\n",
    "        current_map[(8, 5)] = 5\n",
    "        current_map[(9, 5)] = 5\n",
    "        current_map[self.win_state] = 8\n",
    "\n",
    "        # animate the run!\n",
    "        for i in range(len(sequence)):\n",
    "            time.sleep(0.5)\n",
    "            if i == 0:\n",
    "                current_map[sequence[i]] = 1\n",
    "                clear_output(wait=True)\n",
    "                print(0)\n",
    "                print(current_map)\n",
    "            else:\n",
    "                current_map[sequence[i-1]] = 0\n",
    "                current_map[sequence[i]] = 1\n",
    "                clear_output(wait=True)\n",
    "                print(i)\n",
    "                print(current_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will use Downing fig 12 for testing on this\n",
    "class Figure12:\n",
    "    def __init__ (self, rows, cols, win_state, start_state):\n",
    "        self.memory = []\n",
    "        self.memory_position = 0\n",
    "        self.memory_limit = 20\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.start_state = start_state\n",
    "        self.win_state = win_state\n",
    "        self.current_state = self.start_state\n",
    "        \n",
    "    def sample_action (self):\n",
    "        rand = random.uniform(0, 1)\n",
    "        if (rand >= 0) and (rand < 0.25):\n",
    "            return 0\n",
    "        elif (rand >= 0.25) and (rand < 0.5):\n",
    "            return 1\n",
    "        elif (rand >= 0.5) and (rand < 0.75):\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "        \n",
    "    def reset (self):\n",
    "        self.current_state = self.start_state\n",
    "        return self.current_state\n",
    "        \n",
    "    # just reset for now...\n",
    "    def close (self):\n",
    "        self.current_state = self.start_state\n",
    "        return 1\n",
    "    \n",
    "    def check_win (self):\n",
    "        if self.current_state == self.win_state:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def step (self, action):\n",
    "        # north\n",
    "        if action == 0:\n",
    "            next = (self.current_state[0] - 1, self.current_state[1])\n",
    "        # south\n",
    "        elif action == 1:\n",
    "            next = (self.current_state[0] + 1, self.current_state[1])\n",
    "        # east\n",
    "        elif action == 2:\n",
    "            next = (self.current_state[0], self.current_state[1] + 1)\n",
    "        # west\n",
    "        else:\n",
    "            next = (self.current_state[0], self.current_state[1] - 1)\n",
    "\n",
    "        terminate = False\n",
    "        reward = 0\n",
    "        # check if move is legal\n",
    "        if (next[0] >= 0 and next[0] <= (self.rows-1)) and (next[1] >= 0 and next[1] <= (self.cols-1)):            \n",
    "            illegal = 0\n",
    "            if (next == (2, 0)) or (next == (1, 1)) or (next == (2, 1)) or (next == (1, 3)) or (next == (2, 3)) or (next == (2, 4)):\n",
    "                illegal = 1\n",
    "                    \n",
    "            if (illegal == 0):\n",
    "                self.current_state = next\n",
    "                reward += 0.1\n",
    "                #reward -= 0.01\n",
    "            else:\n",
    "                reward -= 0.01\n",
    "                #reward -= 1\n",
    "                #reward = reward\n",
    "        else:\n",
    "            reward -= 0.01\n",
    "            #reward -= 1\n",
    "            #reward = reward\n",
    "            \n",
    "        # punish repeat states within last 20 states\n",
    "        if self.current_state in self.memory:\n",
    "            reward -= 0.01\n",
    "            #reward -= 1\n",
    "            #reward = reward\n",
    "        \n",
    "        if self.check_win():\n",
    "            reward += 100\n",
    "            terminate = True\n",
    "        \n",
    "        # add new state to memory\n",
    "        if len(self.memory) <= self.memory_limit:\n",
    "            (self.memory).append(self.current_state)\n",
    "        # after memory is full, begin overriding it\n",
    "        else:\n",
    "            if self.memory_position < self.memory_limit:\n",
    "                self.memory[self.memory_position] = self.current_state\n",
    "                self.memory_position += 1\n",
    "            else:\n",
    "                self.memory_position = 0\n",
    "                self.memory[self.memory_position] = self.current_state\n",
    "        \n",
    "        return self.current_state, reward, terminate\n",
    "    \n",
    "    def animate_path(self, sequence):\n",
    "        current_map = np.zeros((5, 5))\n",
    "        # add barrier\n",
    "        current_map[(2, 0)] = 5\n",
    "        current_map[(1, 1)] = 5\n",
    "        current_map[(2, 1)] = 5\n",
    "        current_map[(1, 3)] = 5\n",
    "        current_map[(2, 3)] = 5\n",
    "        current_map[(2, 4)] = 5\n",
    "        current_map[self.win_state] = 8\n",
    "\n",
    "        # animate the run!\n",
    "        for i in range(len(sequence)):\n",
    "            time.sleep(0.5)\n",
    "            if i == 0:\n",
    "                current_map[sequence[i]] = 1\n",
    "                clear_output(wait=True)\n",
    "                print(0)\n",
    "                print(current_map)\n",
    "            else:\n",
    "                current_map[sequence[i-1]] = 0\n",
    "                current_map[sequence[i]] = 1\n",
    "                clear_output(wait=True)\n",
    "                print(i)\n",
    "                print(current_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will use Downing fig 13 for testing on this\n",
    "class Figure13:\n",
    "    def __init__ (self, rows, cols, win_state, start_state):\n",
    "        self.memory = []\n",
    "        self.memory_position = 0\n",
    "        self.memory_limit = 20\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.start_state = start_state\n",
    "        self.win_state = win_state\n",
    "        self.current_state = self.start_state\n",
    "        \n",
    "    def sample_action (self):\n",
    "        rand = random.uniform(0, 1)\n",
    "        if (rand >= 0) and (rand < 0.25):\n",
    "            return 0\n",
    "        elif (rand >= 0.25) and (rand < 0.5):\n",
    "            return 1\n",
    "        elif (rand >= 0.5) and (rand < 0.75):\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "        \n",
    "    def reset (self):\n",
    "        self.current_state = self.start_state\n",
    "        return self.current_state\n",
    "        \n",
    "    # just reset for now...\n",
    "    def close (self):\n",
    "        self.current_state = self.start_state\n",
    "        return 1\n",
    "    \n",
    "    def check_win (self):\n",
    "        if self.current_state == self.win_state:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def step (self, action):\n",
    "        # north\n",
    "        if action == 0:\n",
    "            next = (self.current_state[0] - 1, self.current_state[1])\n",
    "        # south\n",
    "        elif action == 1:\n",
    "            next = (self.current_state[0] + 1, self.current_state[1])\n",
    "        # east\n",
    "        elif action == 2:\n",
    "            next = (self.current_state[0], self.current_state[1] + 1)\n",
    "        # west\n",
    "        else:\n",
    "            next = (self.current_state[0], self.current_state[1] - 1)\n",
    "\n",
    "        terminate = False\n",
    "        reward = 0\n",
    "        # check if move is legal\n",
    "        if (next[0] >= 0 and next[0] <= (self.rows-1)) and (next[1] >= 0 and next[1] <= (self.cols-1)):            \n",
    "            illegal = 0\n",
    "            if (next == (2, 0)) or (next == (1, 1)) or (next == (2, 1)) or (next == (1, 3)) or (next == (2, 3)) or (next == (3, 3)) or (next == (3, 4)):\n",
    "                illegal = 1\n",
    "                    \n",
    "            if (illegal == 0):\n",
    "                self.current_state = next\n",
    "                reward += 0.1\n",
    "                #reward -= 0.01\n",
    "            else:\n",
    "                reward -= 0.01\n",
    "                #reward -= 1\n",
    "                #reward = reward\n",
    "        else:\n",
    "            reward -= 0.01\n",
    "            #reward -= 1\n",
    "            #reward = reward\n",
    "            \n",
    "        # punish repeat states within last 20 states\n",
    "        if self.current_state in self.memory:\n",
    "            reward -= 0.01\n",
    "            #reward -= 1\n",
    "            #reward = reward\n",
    "        \n",
    "        if self.check_win():\n",
    "            reward += 100\n",
    "            terminate = True\n",
    "        \n",
    "        # add new state to memory\n",
    "        if len(self.memory) <= self.memory_limit:\n",
    "            (self.memory).append(self.current_state)\n",
    "        # after memory is full, begin overriding it\n",
    "        else:\n",
    "            if self.memory_position < self.memory_limit:\n",
    "                self.memory[self.memory_position] = self.current_state\n",
    "                self.memory_position += 1\n",
    "            else:\n",
    "                self.memory_position = 0\n",
    "                self.memory[self.memory_position] = self.current_state\n",
    "        \n",
    "        return self.current_state, reward, terminate\n",
    "    \n",
    "    def animate_path(self, sequence):\n",
    "        current_map = np.zeros((5, 5))\n",
    "        # add barrier\n",
    "        current_map[(2, 0)] = 5\n",
    "        current_map[(1, 1)] = 5\n",
    "        current_map[(2, 1)] = 5\n",
    "        current_map[(1, 3)] = 5\n",
    "        current_map[(2, 3)] = 5\n",
    "        current_map[(3, 3)] = 5\n",
    "        current_map[(3, 4)] = 5\n",
    "        current_map[self.win_state] = 8\n",
    "\n",
    "        # animate the run!\n",
    "        for i in range(len(sequence)):\n",
    "            time.sleep(0.5)\n",
    "            if i == 0:\n",
    "                current_map[sequence[i]] = 1\n",
    "                clear_output(wait=True)\n",
    "                print(0)\n",
    "                print(current_map)\n",
    "            else:\n",
    "                current_map[sequence[i-1]] = 0\n",
    "                current_map[sequence[i]] = 1\n",
    "                clear_output(wait=True)\n",
    "                print(i)\n",
    "                print(current_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate (team, state, epsilon):\n",
    "    top_learner = None\n",
    "    action = None   \n",
    "\n",
    "    # get best learner\n",
    "    actVars = {'frameNum':random.randrange(0, 100000000)}\n",
    "\n",
    "    #valid_learners = [lrnr for lrnr in team.learners if lrnr.isActionAtomic()]\n",
    "    valid_learners = [lrnr for lrnr in team.learners]\n",
    "    \n",
    "    top_learner = max(valid_learners, key=lambda lrnr: lrnr.bid(state, actVars=actVars))\n",
    "    \n",
    "    if top_learner == None:\n",
    "        print('No top learner found!')\n",
    "        return None, 0\n",
    "    else:\n",
    "        actions = []\n",
    "        top_q = 0\n",
    "        top_action = None\n",
    "        \n",
    "        for entry in team.q_table:\n",
    "            if entry['learner'] == str(top_learner.id):\n",
    "                actions.append(entry['action'])\n",
    "                if entry['q'] >= top_q: # greater than OR greater than or equal to??\n",
    "                    top_q = entry['q']\n",
    "                    top_action = entry['action']            \n",
    "#         print('------------------------')\n",
    "#         print('action code: ' + str(top_learner.actionObj.actionCode))\n",
    "#         print('Actions:')\n",
    "#         print(actions)\n",
    "#         print('------------------------')\n",
    "        # e greedy action selection\n",
    "        e_prob = random.uniform(0, 1)\n",
    "        \n",
    "#         if (len(actions) == 0):\n",
    "#             print('NO ACTIONS!!!!!!')\n",
    "#             print(team.learners)\n",
    "#             for entry in team.q_table:\n",
    "#                 print(entry)\n",
    "#                 print('-')\n",
    "#             print('NO ACTIONS!!!!!!')\n",
    "\n",
    "        if e_prob < epsilon:\n",
    "            if len(actions) == 1:\n",
    "                action = actions[0]\n",
    "            else:\n",
    "                rand_action = random.randint(0, len(actions)-1)\n",
    "                action = actions[rand_action]\n",
    "        else:\n",
    "            # select action with highest q value from top learner's actions\n",
    "            action = top_action\n",
    "    #print(action)\n",
    "    return top_learner, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update (team, next_learner, action, learner, reward, alpha, discount):\n",
    "    \n",
    "    # find the greatest q value out of possible actions for learner t+1\n",
    "    second_max_q = 0\n",
    "    for second_learner in team.q_table:\n",
    "        if second_learner['learner'] == str(next_learner.id):\n",
    "            if second_learner['q'] > second_max_q:\n",
    "                second_max_q = second_learner['q']\n",
    "    \n",
    "    # find the current learner and q update\n",
    "    for first_learner in team.q_table:\n",
    "        if first_learner['learner'] == str(learner.id) and first_learner['action'] == action:\n",
    "            # equation 1 from tpg pdf\n",
    "            first_learner['q'] += alpha * (reward + (discount * second_max_q) - first_learner['q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fitness (env_name, team, env, epsilon, alpha, discount):\n",
    "    l_t, a_t = evaluate(team, env.current_state, epsilon)\n",
    "    t = 0\n",
    "    if env_name == 'fig9':\n",
    "        t_max = 100\n",
    "    else:\n",
    "        t_max = 50\n",
    "    total_reward = 0\n",
    "    while t < t_max:\n",
    "        s_next, reward, isDone = env.step(a_t)\n",
    "        total_reward += reward\n",
    "        if isDone:\n",
    "            return total_reward\n",
    "        \n",
    "        l_next, a_next = evaluate(team, env.current_state, epsilon)\n",
    "        if l_t.id != l_next.id:\n",
    "            update(team, l_next, a_t, l_t, reward, alpha, discount)\n",
    "        a_t = a_next\n",
    "        l_t = l_next\n",
    "        t = t + 1\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tpg imports\n",
    "# import to do training\n",
    "from tpg.trainer import Trainer\n",
    "# import to run an agent (always needed)\n",
    "from tpg.agent import Agent\n",
    "# visual tools\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# for writing\n",
    "import csv\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions distribution tracker\n",
    "# each index corresponds to its actions\n",
    "# the values are the amount of times that action has been sampled\n",
    "# action_counts = [0, 0, 0, 0]\n",
    "# current_distribution = []\n",
    "\n",
    "def action_distribution(counts):\n",
    "    total = 0\n",
    "    proportions = []\n",
    "    for action in counts:\n",
    "        proportion = 1 / action\n",
    "        proportion = int(proportion * 10 * sum(counts))\n",
    "        total += proportion\n",
    "        proportions.append(proportion)\n",
    "    \n",
    "    return total, proportions  \n",
    "\n",
    "# this function will sample actions in a way that is biased to the least sampled actions\n",
    "def sample_action(total, proportions):\n",
    "    \n",
    "    sample = random.randint(1, total)\n",
    "    \n",
    "    if (sample > 1) and (sample <= proportions[0]):\n",
    "        return 0\n",
    "    elif (sample > proportions[0]) and (sample <= proportions[0] + proportions[1]):\n",
    "        return 1\n",
    "    elif (sample > proportions[0] + proportions[1]) and (sample <= proportions[0] + proportions[1] + proportions[2]):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = [0, 0, 0, 0]\n",
    "# dist_total, dist = action_distribution([1, 3, 4, 5])\n",
    "# for i in range(100):\n",
    "#     sample = sample_action(dist_total, dist)\n",
    "#     if sample == 0:\n",
    "#         counts[0] += 1\n",
    "#     elif sample == 1:\n",
    "#         counts[1] += 1\n",
    "#     elif sample == 2:\n",
    "#         counts[2] += 1\n",
    "#     elif sample == 3:\n",
    "#         counts[3] += 1\n",
    "# print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q table helper functions\n",
    "def create (agents, gen):\n",
    "    for agent in agents:\n",
    "        team = agent.team\n",
    "        for learner in team.learners:\n",
    "            # randomize actions of the learners\n",
    "            action_list = [0, 1, 2, 3]\n",
    "            \n",
    "            random.shuffle(action_list)\n",
    "            actions = random.randint(1,4)\n",
    "            for i in range(actions):\n",
    "                (team.q_table).append({'learner': str(learner.id), 'action': action_list[i], 'q': 0, 'gen': gen})\n",
    "                action_counts[action_list[i]] += 1\n",
    "    return action_counts\n",
    "#         print('---------------------')\n",
    "#         print(team.learners)\n",
    "#         for entry in team.q_table:\n",
    "#             print(entry)\n",
    "#             print('-')\n",
    "#         print('---------------------')\n",
    "\n",
    "# add new learners upon evolution\n",
    "def evolve (agents, lemarkian, gen, action_counts, action_dist_total, action_dist):\n",
    "    if gen % 5 == 0:\n",
    "        action_dist_total, action_dist = action_distribution(action_counts)\n",
    "    \n",
    "    for agent in agents:\n",
    "        team = agent.team\n",
    "        for learner in team.learners:   \n",
    "            \n",
    "            found = 0\n",
    "            for entry in team.q_table:\n",
    "                if entry['learner'] == str(learner.id):\n",
    "                    found = 1\n",
    "            \n",
    "            if found == 0:\n",
    "                parent_actions = []\n",
    "\n",
    "                if team.parentTeam:\n",
    "                    # grab the actions from the parent learner\n",
    "                    parent_actions = [entry for entry in (team.parentTeam).q_table if entry['learner'] == str(learner.id) and entry['gen'] == gen-1] \n",
    "\n",
    "                if parent_actions:\n",
    "                    for entry in parent_actions:\n",
    "                        (team.q_table).append({'learner':str(learner.id), 'action':entry['action'], 'q':entry['q'], 'gen':gen, 'lemark':1})\n",
    "                        # increment the sampled actions count\n",
    "                        action_counts[entry['action']] += 1\n",
    "                else:\n",
    "\n",
    "                    # let the actions converge a bit before sampling\n",
    "                    if (gen > 30):\n",
    "                        # new way of sampling!\n",
    "                        actions = random.randint(1,4)\n",
    "                        action_list = []\n",
    "                        for i in range(actions):\n",
    "                            action_list.append(sample_action(action_dist_total, action_dist))\n",
    "                    else:\n",
    "                        action_list = [0, 1, 2, 3]\n",
    "                        random.shuffle(action_list)\n",
    "                        actions = random.randint(1,4)\n",
    "                    \n",
    "                    for i in range(actions):\n",
    "                        (team.q_table).append({'learner':str(learner.id), 'action': action_list[i], 'q': 0, 'gen': gen, 'lemark':0})\n",
    "                        action_counts[entry['action']] += 1\n",
    "    \n",
    "    return action_counts, action_dist, action_dist_total\n",
    "\n",
    "\n",
    "def clean (agents, current_gen):\n",
    "    for agent in agents:\n",
    "        team = agent.team\n",
    "        for entry in team.q_table:\n",
    "            if entry['gen'] < (current_gen):\n",
    "                (team.q_table).remove(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "Champ fitness: 9.01999999999999\n",
      "Champ fitness: 9.05999999999999\n"
     ]
    }
   ],
   "source": [
    "runs = 1\n",
    "lemarkian = 1\n",
    "save = 0\n",
    "for run in range(runs):\n",
    "    print(run)\n",
    "    trainer = Trainer(actions=4, teamPopSize=50, pActAtom=1.0, \n",
    "                      nRegisters=4, initMaxActProgSize=48, \n",
    "                      initMaxTeamSize=2, maxTeamSize=5, gap=0.5) # initMaxTeamSize=2, maxTeamSize=5\n",
    "\n",
    "    # init environment\n",
    "    envName = 'fig9'\n",
    "    env = Figure9(10, 10, (5, 9), (9, 3))\n",
    "#     envName = 'fig11'\n",
    "#     env = Figure11(5, 5, (0, 4), (4, 0))\n",
    "#     envName = 'fig12'\n",
    "#     env = Figure12(5, 5, (0, 4), (4, 0))\n",
    "#     envName = 'fig13'\n",
    "#     env = Figure13(5, 5, (2, 4), (4, 0))\n",
    "\n",
    "    # init tracking tools\n",
    "    allScores = []\n",
    "    num_gen = 300\n",
    "    champion = None\n",
    "    best_score = -10000000\n",
    "\n",
    "    # parameters\n",
    "    alpha = 0.1\n",
    "    epsilon = 0.1\n",
    "    discount = 0.9\n",
    "\n",
    "    # init samplers\n",
    "    action_counts = [1, 1, 1, 1]\n",
    "    action_dist = [0, 0, 0, 0]\n",
    "    action_dist_total = 0\n",
    "\n",
    "    for gen in range(num_gen):\n",
    "        print(gen)\n",
    "        scoreList = []\n",
    "        #print('gen' + str(gen))\n",
    "        agents = trainer.getAgents()\n",
    "\n",
    "        # update q table with new populations\n",
    "        if gen == 0:\n",
    "            actions_counts = create(agents, gen)\n",
    "        else:\n",
    "            # lemarkian learning set (set to 0 to turn off)\n",
    "            action_counts, action_dist, action_dist_total = evolve(agents, lemarkian, gen, \n",
    "                                                                   action_counts, action_dist_total, action_dist)\n",
    "            #clean(agents, gen)\n",
    "\n",
    "        for agent in agents:     \n",
    "            team = agent.team\n",
    "            env.reset()\n",
    "            fitness = evaluate_fitness(envName, team, env, epsilon, alpha, discount)\n",
    "\n",
    "            # save champion on last gen\n",
    "            if gen == (num_gen - 1):\n",
    "                if fitness > best_score:\n",
    "                    best_score = fitness\n",
    "                    print('Champ fitness: ' + str(fitness))\n",
    "                    champion = team\n",
    "#                 for entry in champion.q_table:\n",
    "#                     print(entry)\n",
    "#                     print('--')\n",
    "\n",
    "            # apply scores\n",
    "            agent.reward(fitness, envName)\n",
    "            scoreList.append((agent.team.id, agent.team.outcomes))\n",
    "\n",
    "        # evolution :)\n",
    "        teams = trainer.applyScores(scoreList)\n",
    "        trainer.evolve(tasks=[envName])\n",
    "\n",
    "        # scores!\n",
    "        scoreStats = trainer.fitnessStats\n",
    "        allScores.append((scoreStats['min'], scoreStats['max'], scoreStats['average']))\n",
    "\n",
    "    # collect average and max scores to save to csv\n",
    "    if save == 1:\n",
    "        averages = []\n",
    "        maxes = []\n",
    "        for score in allScores:\n",
    "            averages.append(score[2])\n",
    "            maxes.append(score[1])    \n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'average_score': averages,\n",
    "            'max_score': maxes,\n",
    "        })\n",
    "\n",
    "        if lemarkian == 0:\n",
    "            df.to_csv('../results/'+str(envName)+'/qtpg/'+str(run)+'.csv')\n",
    "        else:\n",
    "            df.to_csv('../results/'+str(envName)+'/lqtpg/'+str(run)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in range(num_gen):\n",
    "    x.append(i)\n",
    "\n",
    "for score in allScores:\n",
    "    y.append(score[2])\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Average Score')\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all q values that correspond to given team\n",
    "def find_team_q (q_table, team):\n",
    "    result = []  \n",
    "    for entry in q_table.q:\n",
    "        if entry['team'] == str(team.id):\n",
    "            result.append(entry)\n",
    "    return result\n",
    "\n",
    "# TODO better organize this for quicker analysis\n",
    "def display_q (result):\n",
    "    for entry in result:\n",
    "        print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a given team after training\n",
    "def post_training_run (env_name, team, epsilon, alpha, discount):\n",
    "    env.reset()\n",
    "    l_t, a_t = evaluate(team, env.current_state, epsilon)\n",
    "    states = []\n",
    "    print(states)\n",
    "    states.append(env.current_state)    \n",
    "    t = 0\n",
    "    if env_name == 'fig9':\n",
    "        t_max = 100\n",
    "    else:\n",
    "        t_max = 50\n",
    "    total_reward = 0\n",
    "    while t < t_max:\n",
    "        s_next, reward, isDone = env.step(a_t)\n",
    "        states.append(s_next)\n",
    "        total_reward += reward\n",
    "        if isDone:\n",
    "            return states, total_reward\n",
    "        l_next, a_next = evaluate(team, env.current_state, epsilon)\n",
    "        print('State: ' + str(s_next) + ' Action: ' + str(a_next))\n",
    "        if l_t.id != l_next.id:\n",
    "            print('Switching Learners!')\n",
    "            print('Learner: ' + str(l_next.id))\n",
    "            update(team, l_next, a_t, l_t, reward, alpha, epsilon)\n",
    "        a_t = a_next\n",
    "        l_t = l_next\n",
    "        t = t + 1\n",
    "    return states, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learner': '4708f7fa-f2f9-4c81-8647-acc92239ff32', 'action': 0, 'q': 0.8694819453104586, 'gen': 284, 'lemark': 0}\n",
      "{'learner': '4708f7fa-f2f9-4c81-8647-acc92239ff32', 'action': 2, 'q': 0.9001585091592827, 'gen': 284, 'lemark': 0}\n",
      "{'learner': '4708f7fa-f2f9-4c81-8647-acc92239ff32', 'action': 2, 'q': 0.9001585091592827, 'gen': 284, 'lemark': 0}\n",
      "{'learner': '41e699fa-752c-4abb-8f49-e9422832093f', 'action': 3, 'q': 0.9002078841069991, 'gen': 284, 'lemark': 0}\n",
      "{'learner': '8aa13065-3d7f-417e-9f7a-d73c0a3afcc4', 'action': 1, 'q': 0.026595604337709917, 'gen': 284, 'lemark': 0}\n",
      "{'learner': '8aa13065-3d7f-417e-9f7a-d73c0a3afcc4', 'action': 3, 'q': 0.5308881042278208, 'gen': 284, 'lemark': 0}\n",
      "{'learner': '2bfb3d5e-7e68-4b5a-b903-f4e3a67434ec', 'action': 3, 'q': 0, 'gen': 284, 'lemark': 0}\n",
      "{'learner': '5d2b26ad-bcca-42c4-a8d2-4739dd012390', 'action': 1, 'q': 0, 'gen': 284, 'lemark': 0}\n",
      "4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "41e699fa-752c-4abb-8f49-e9422832093f\n",
      "8aa13065-3d7f-417e-9f7a-d73c0a3afcc4\n",
      "2bfb3d5e-7e68-4b5a-b903-f4e3a67434ec\n",
      "5d2b26ad-bcca-42c4-a8d2-4739dd012390\n"
     ]
    }
   ],
   "source": [
    "# run tests on champion\n",
    "display_q(champion.q_table)\n",
    "for learner in champion.learners:\n",
    "    print(learner.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "State: (9, 2) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (9, 3) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (9, 2) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (8, 2) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (8, 1) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (8, 2) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (8, 1) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (7, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (7, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (7, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (7, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (6, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (6, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (6, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (6, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (6, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (6, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (5, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (5, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (4, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (4, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (4, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (4, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (3, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (3, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (3, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (3, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (2, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (2, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (2, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (2, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (1, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (1, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (1, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (1, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 0\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 0) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "State: (0, 0) Action: 2\n",
      "Switching Learners!\n",
      "Learner: 4708f7fa-f2f9-4c81-8647-acc92239ff32\n",
      "State: (0, 1) Action: 3\n",
      "Switching Learners!\n",
      "Learner: 41e699fa-752c-4abb-8f49-e9422832093f\n",
      "5.989999999999999\n"
     ]
    }
   ],
   "source": [
    "# uses same epsilon, alpha, and discount values as defined prior\n",
    "states, score = post_training_run(envName, champion, epsilon, alpha, discount)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 5. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 5. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 5. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 5. 5.]\n",
      " [0. 0. 5. 5. 5. 5. 0. 0. 5. 8.]\n",
      " [0. 0. 0. 0. 0. 5. 0. 0. 5. 0.]\n",
      " [0. 0. 0. 0. 0. 5. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 5. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 5. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "env.animate_path(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
